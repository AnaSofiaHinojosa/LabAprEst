{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e0075d",
   "metadata": {},
   "source": [
    "# Examen Clasificación \n",
    "## Ana Sofía Hinojosa Bale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "66ffced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7825551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "color1 = ['palevioletred', 'maroon', 'darkslategrey']\n",
    "color2 = ['cadetblue', 'darkcyan', 'darkslategrey']\n",
    "color3 = ['mediumpurple', 'rebeccapurple', 'darkslategrey']\n",
    "color4 = ['steelblue', 'royalblue', 'darkslategrey']\n",
    "\n",
    "\n",
    "def iteracion(funcion, X, Y, Z, x, y, z, n_iter=5, tipo=\"reducir incertidumbre\", color=color1, nivel_conf=0.95):\n",
    "    X = np.asarray(X).reshape(-1, 1)\n",
    "    Y = np.asarray(Y).reshape(-1, 1)\n",
    "    Z = np.asarray(Z).reshape(-1, 1)\n",
    "    x = np.asarray(x).reshape(-1, 1)\n",
    "    y = np.asarray(y).reshape(-1, 1)\n",
    "    z = np.asarray(z).reshape(-1, 1)\n",
    "    y = funcion(X, Y, Z).ravel()\n",
    "\n",
    "    kernel = 1 * RBF(length_scale=1.0)\n",
    "    gp = GPR(kernel=kernel, n_restarts_optimizer=10)\n",
    "    gp.fit(X, y)\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        y_pred, std = gp.predict(x, return_std=True)\n",
    "        y_pred = y_pred.ravel()\n",
    "        nivel_confianza = nivel_conf\n",
    "        nc = norm.ppf(1 - (1 - nivel_confianza) / 2)\n",
    "        # nc = 2.575\n",
    "        y_upper = y_pred + nc * std\n",
    "        y_lower = y_pred - nc * std\n",
    "\n",
    "        if tipo == \"reducir incertidumbre\":\n",
    "            index = np.argmax(std)\n",
    "        elif tipo == \"maximizar\":\n",
    "            index = np.argmax(y_upper)\n",
    "        elif tipo == \"minimizar\":\n",
    "            index = np.argmin(y_lower)\n",
    "        x_val = x[index].reshape(1, -1)\n",
    "        y_val = funcion(x_val).ravel()[0]\n",
    "\n",
    "        X = np.vstack([X, x_val])\n",
    "        y = np.concatenate([y, np.array([y_val])])\n",
    "\n",
    "        gp.fit(X, y)\n",
    "\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        plt.plot(x.ravel(), y_pred, c=color[0], lw=2, label=\"Predicción GP\")\n",
    "        plt.plot(x.ravel(), funcion(x).ravel(),\n",
    "                 c=\"lightgray\", ls=\"--\", label=\"Función real\")\n",
    "\n",
    "        if X.shape[0] > 1:\n",
    "            plt.scatter(X[:-1].ravel(), funcion(X[:-1]).ravel(),\n",
    "                        c=color[1], label=\"Datos anteriores\")\n",
    "\n",
    "        plt.scatter(X[-1].ravel(), y_val, c=color[2], label=\"Nuevo punto\")\n",
    "\n",
    "        plt.plot(x.ravel(), y_upper, ls=\":\", lw=1,\n",
    "                 color=color[0], label=f\"IC {nivel_confianza*100:.0f}%, z={nc:.2f}\")\n",
    "        plt.plot(x.ravel(), y_lower, ls=\":\", lw=1, color=color[0])\n",
    "        plt.fill_between(x.ravel(), y_lower, y_upper,\n",
    "                         alpha=0.2, color=color[0])\n",
    "\n",
    "        plt.grid(linestyle=\":\", alpha=0.7)\n",
    "        plt.suptitle(f\"Regresión con proceso gaussiano - Iteración {i+1}\")\n",
    "        plt.title(f\"Selección de nuevo punto con criterio '{tipo}'\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"f(x)\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "db7d610b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def f(x, y, z) :\\n    return (6*x -2)**2 * np.sin(12*x -4) + (6*y -2)**2 * np.cos(12*y -4) + (6*z -2)**2 * np.sin(12*z -4)\\nnp.random.seed(10)\\nX = np.random.uniform(0, 1, 3).reshape([-1, 1])\\nY = np.random.uniform(0, 1, 3).reshape([-1, 1])\\nZ = np.random.uniform(0, 1, 3).reshape([-1, 1]) \\nx = np.linspace(0, 1, 1000).reshape([-1, 1])\\ny = np.linspace(0, 1, 1000).reshape([-1, 1])\\nz = np.linspace(0, 1, 1000).reshape([-1, 1])\\n\\niteracion(f, X, Y, Z, x, y, z, n_iter=30)'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def f(x, y, z) :\n",
    "    return (6*x -2)**2 * np.sin(12*x -4) + (6*y -2)**2 * np.cos(12*y -4) + (6*z -2)**2 * np.sin(12*z -4)\n",
    "np.random.seed(10)\n",
    "X = np.random.uniform(0, 1, 3).reshape([-1, 1])\n",
    "Y = np.random.uniform(0, 1, 3).reshape([-1, 1])\n",
    "Z = np.random.uniform(0, 1, 3).reshape([-1, 1]) \n",
    "x = np.linspace(0, 1, 1000).reshape([-1, 1])\n",
    "y = np.linspace(0, 1, 1000).reshape([-1, 1])\n",
    "z = np.linspace(0, 1, 1000).reshape([-1, 1])\n",
    "\n",
    "iteracion(f, X, Y, Z, x, y, z, n_iter=30)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28149a42",
   "metadata": {},
   "source": [
    "# Pregunta 2\n",
    "Valor a predecir: average_rating>=4.3 -> 1, < 4.3 -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f28d603e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selling_price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>availability</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>country</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>25.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>25.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>80.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>80.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>72</td>\n",
       "      <td>120.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>70</td>\n",
       "      <td>100.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>35</td>\n",
       "      <td>50.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>70</td>\n",
       "      <td>100.0</td>\n",
       "      <td>InStock</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>adidas</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>829 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     selling_price  original_price availability  category   brand country  \\\n",
       "0               20            25.0      InStock  Clothing  adidas     USA   \n",
       "1               20            25.0      InStock  Clothing  adidas     USA   \n",
       "2               20            25.0      InStock  Clothing  adidas     USA   \n",
       "3               48            80.0      InStock  Clothing  adidas     USA   \n",
       "4               64            80.0      InStock     Shoes  adidas     USA   \n",
       "..             ...             ...          ...       ...     ...     ...   \n",
       "824             72           120.0      InStock     Shoes  adidas     USA   \n",
       "825             70           100.0      InStock     Shoes  adidas     USA   \n",
       "826             35            50.0      InStock     Shoes  adidas     USA   \n",
       "827             40            50.0      InStock     Shoes  adidas     USA   \n",
       "828             70           100.0      InStock     Shoes  adidas     USA   \n",
       "\n",
       "     average_rating  reviews_count  \n",
       "0                 1            116  \n",
       "1                 1            116  \n",
       "2                 1            116  \n",
       "3                 0            144  \n",
       "4                 1            160  \n",
       "..              ...            ...  \n",
       "824               1            151  \n",
       "825               1            135  \n",
       "826               1            190  \n",
       "827               1            190  \n",
       "828               1            135  \n",
       "\n",
       "[829 rows x 8 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('adidas.csv')\n",
    "data = data.drop(columns=['url', 'name', 'sku', 'description', 'images', 'source_website', 'source', 'breadcrumbs', 'language', 'currency', 'color', 'crawled_at'])\n",
    "data['original_price'] = data['original_price'].str.replace('$', '').astype(float)\n",
    "data['average_rating'] = data['average_rating'].apply(lambda x: 1 if x >= 4.3 else 0)\n",
    "num_col = ['selling_price', 'original_price', 'reviews_count']\n",
    "cat_col = ['availability', 'category', 'brand', 'country']\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "72bece66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['average_rating'])\n",
    "X = pd.get_dummies(X, columns=cat_col, drop_first=True)\n",
    "y = data['average_rating']\n",
    "x_test, x_train, y_test, y_train = train_test_split(X, y, train_size=0.7, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "04acd76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selling_price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>availability_OutOfStock</th>\n",
       "      <th>category_Clothing</th>\n",
       "      <th>category_Shoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>53</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>32</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1352</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>24</td>\n",
       "      <td>30.0</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>28</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7291</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>44</td>\n",
       "      <td>55.0</td>\n",
       "      <td>177</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>48</td>\n",
       "      <td>60.0</td>\n",
       "      <td>214</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>28</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3812</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>52</td>\n",
       "      <td>65.0</td>\n",
       "      <td>671</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>44</td>\n",
       "      <td>55.0</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>24</td>\n",
       "      <td>30.0</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     selling_price  original_price  reviews_count  availability_OutOfStock  \\\n",
       "145             18            30.0             53                    False   \n",
       "306             32            35.0           1352                    False   \n",
       "234             24            30.0             78                    False   \n",
       "220             28            35.0           7291                    False   \n",
       "819             44            55.0            177                    False   \n",
       "..             ...             ...            ...                      ...   \n",
       "71              48            60.0            214                    False   \n",
       "106             28            35.0           3812                    False   \n",
       "270             52            65.0            671                    False   \n",
       "435             44            55.0             17                    False   \n",
       "102             24            30.0             78                    False   \n",
       "\n",
       "     category_Clothing  category_Shoes  \n",
       "145               True           False  \n",
       "306               True           False  \n",
       "234               True           False  \n",
       "220              False            True  \n",
       "819              False            True  \n",
       "..                 ...             ...  \n",
       "71                True           False  \n",
       "106              False            True  \n",
       "270               True           False  \n",
       "435              False            True  \n",
       "102               True           False  \n",
       "\n",
       "[580 rows x 6 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "38448ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(x_train[num_col])\n",
    "x_train[num_col] = scaler.transform(x_train[num_col])\n",
    "x_test[num_col] = scaler.transform(x_test[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "658f5ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7683724509426701"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresion = LogisticRegression()\n",
    "regresion.fit(x_train,y_train)\n",
    "y_pred = regresion.predict_proba(x_train)[:, 1]\n",
    "roc_auc = roc_auc_score(y_train, y_pred)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c3a86de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6790495049504951"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = regresion.predict_proba(x_test)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "roc_auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "917b859f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 6)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "n,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40c649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cf014f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.03231624])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4a940f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.0323162415112948)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "93005276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n = x_train.shape[0]\\np = x_train.shape[1]\\nRSS = np.sum((y_pred_test - y_test)**2)\\nvar = RSS / (n - p - 1)\\n\\nb_0 = regresion.intercept_\\nb_i = regresion.coef_\\n\\nX = np.column_stack((np.ones(n), x_train))\\nX = X.astype(float)\\nvar_beta = np.linalg.inv(X.T @ X + np.eye(X.shape[1])*1e-6) * var\\nstd_beta = np.sqrt(np.diag(var_beta))\\nt_stats = np.zeros(len(std_beta))\\nfor i in range(len(std_beta)):\\n    t_stats[i] = (b_0[0] - b_i[0][i]) / std_beta[i]\\np_values = [2 * (1 - stats.t.cdf(np.abs(t), n - p - 1)) for t in t_stats]'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "RSS = np.sum((y_pred_test - y_test)**2)\n",
    "var = RSS / (n - p - 1)\n",
    "\n",
    "b_0 = regresion.intercept_\n",
    "b_i = regresion.coef_\n",
    "\n",
    "X = np.column_stack((np.ones(n), x_train))\n",
    "X = X.astype(float)\n",
    "var_beta = np.linalg.inv(X.T @ X + np.eye(X.shape[1])*1e-6) * var\n",
    "std_beta = np.sqrt(np.diag(var_beta))\n",
    "t_stats = np.zeros(len(std_beta))\n",
    "for i in range(len(std_beta)):\n",
    "    t_stats[i] = (b_0[0] - b_i[0][i]) / std_beta[i]\n",
    "p_values = [2 * (1 - stats.t.cdf(np.abs(t), n - p - 1)) for t in t_stats]'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25121d87",
   "metadata": {},
   "source": [
    "# Pregunta 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fee95038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.848324</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.123396</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.684422</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.943724</td>\n",
       "      <td>-0.263941</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-1.103255</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.998208</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.123302</td>\n",
       "      <td>-0.494043</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504055</td>\n",
       "      <td>-1.504687</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>1.409746</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.827813</td>\n",
       "      <td>-0.622642</td>\n",
       "      <td>0.356432</td>\n",
       "      <td>1.722735</td>\n",
       "      <td>0.870031</td>\n",
       "      <td>0.115169</td>\n",
       "      <td>-0.908682</td>\n",
       "      <td>2.532136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.547919</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.046245</td>\n",
       "      <td>0.405445</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.610154</td>\n",
       "      <td>-0.398282</td>\n",
       "      <td>-0.531023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.342981</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.279594</td>\n",
       "      <td>-0.735190</td>\n",
       "      <td>-0.685193</td>\n",
       "      <td>-0.275760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>0.159787</td>\n",
       "      <td>-0.470732</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.240205</td>\n",
       "      <td>-0.371101</td>\n",
       "      <td>1.170732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.873019</td>\n",
       "      <td>0.046245</td>\n",
       "      <td>0.656358</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.202129</td>\n",
       "      <td>-0.473785</td>\n",
       "      <td>-0.871374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0       0.639947  0.848324       0.149641       0.907270 -0.692891  0.204013   \n",
       "1      -0.844885 -1.123396      -0.160546       0.530902 -0.692891 -0.684422   \n",
       "2       1.233880  1.943724      -0.263941      -1.288212 -0.692891 -1.103255   \n",
       "3      -0.844885 -0.998208      -0.160546       0.154533  0.123302 -0.494043   \n",
       "4      -1.141852  0.504055      -1.504687       0.907270  0.765836  1.409746   \n",
       "..           ...       ...            ...            ...       ...       ...   \n",
       "763     1.827813 -0.622642       0.356432       1.722735  0.870031  0.115169   \n",
       "764    -0.547919  0.034598       0.046245       0.405445 -0.692891  0.610154   \n",
       "765     0.342981  0.003301       0.149641       0.154533  0.279594 -0.735190   \n",
       "766    -0.844885  0.159787      -0.470732      -1.288212 -0.692891 -0.240205   \n",
       "767    -0.844885 -0.873019       0.046245       0.656358 -0.692891 -0.202129   \n",
       "\n",
       "     DiabetesPedigreeFunction       Age  \n",
       "0                    0.468492  1.425995  \n",
       "1                   -0.365061 -0.190672  \n",
       "2                    0.604397 -0.105584  \n",
       "3                   -0.920763 -1.041549  \n",
       "4                    5.484909 -0.020496  \n",
       "..                        ...       ...  \n",
       "763                 -0.908682  2.532136  \n",
       "764                 -0.398282 -0.531023  \n",
       "765                 -0.685193 -0.275760  \n",
       "766                 -0.371101  1.170732  \n",
       "767                 -0.473785 -0.871374  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "y = df['Outcome']\n",
    "X = df.drop(columns=['Outcome'])\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X), columns=X.columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b4f87ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(x: np.ndarray, y: np.ndarray, C: float) -> dict:\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    lr_model = LogisticRegression(max_iter=1000, C=C)\n",
    "    lr_model.fit(x, y)\n",
    "    lr_scores = cross_val_score(lr_model, x, y, cv=kf, scoring='precision')\n",
    "    lr_predict = lr_model.predict_proba(x)[:, 1]\n",
    "    lr_results = {\n",
    "        'mean': lr_scores.mean(),\n",
    "        'std': lr_scores.std(),\n",
    "        'predictions': lr_predict\n",
    "    }\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"\\nLogistic Regression: Precision = {lr_results['mean']:.4f} ± {lr_results['std']:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'lr_results': lr_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0556879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression: Precision = 0.7200 ± 0.1076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr_results': {'mean': np.float64(0.7200367322735743),\n",
       "  'std': np.float64(0.10757181350095558),\n",
       "  'predictions': array([0.71981638, 0.04933123, 0.79421539, 0.04226898, 0.90041553,\n",
       "         0.14753243, 0.06731905, 0.64097778, 0.7097593 , 0.03721347,\n",
       "         0.22044378, 0.89587106, 0.78299976, 0.63136585, 0.62706761,\n",
       "         0.39906913, 0.37177202, 0.19736995, 0.35667009, 0.23497608,\n",
       "         0.39290264, 0.31760973, 0.93916912, 0.29478265, 0.70111706,\n",
       "         0.44118653, 0.7353875 , 0.04651918, 0.5392435 , 0.27861723,\n",
       "         0.42608398, 0.57257665, 0.04967327, 0.03712914, 0.43217669,\n",
       "         0.15065195, 0.66342646, 0.39336248, 0.17298955, 0.5723509 ,\n",
       "         0.74155082, 0.69469157, 0.11492119, 0.92606855, 0.62715685,\n",
       "         0.95124578, 0.43321492, 0.04038956, 0.38030842, 0.03940934,\n",
       "         0.03682523, 0.08594148, 0.06815446, 0.82610491, 0.70780091,\n",
       "         0.02307931, 0.8817425 , 0.35816004, 0.83150367, 0.18399248,\n",
       "         0.01011081, 0.52045455, 0.02385955, 0.3085604 , 0.35427064,\n",
       "         0.11950116, 0.1934116 , 0.47113114, 0.03254582, 0.30235727,\n",
       "         0.19435476, 0.36412302, 0.81553638, 0.2473451 , 0.05229664,\n",
       "         0.00203153, 0.07719661, 0.22264235, 0.66849353, 0.10099177,\n",
       "         0.10304983, 0.00601279, 0.13816207, 0.05071594, 0.67424721,\n",
       "         0.19287928, 0.52880672, 0.1877996 , 0.78310101, 0.07509597,\n",
       "         0.01963785, 0.25928607, 0.33143355, 0.29688766, 0.25522516,\n",
       "         0.51549517, 0.08263986, 0.01765711, 0.134758  , 0.45204085,\n",
       "         0.83485704, 0.28223551, 0.06336086, 0.03234252, 0.23167185,\n",
       "         0.2473727 , 0.01992434, 0.42494587, 0.10747755, 0.09396762,\n",
       "         0.59968385, 0.70680427, 0.05470041, 0.09417003, 0.73860716,\n",
       "         0.55332091, 0.35675798, 0.15874376, 0.11886339, 0.05344606,\n",
       "         0.88466872, 0.28481945, 0.14988301, 0.35468975, 0.13665439,\n",
       "         0.52528797, 0.45764913, 0.19556077, 0.19544672, 0.15569068,\n",
       "         0.63160321, 0.68322478, 0.67171   , 0.2728204 , 0.05564973,\n",
       "         0.24322143, 0.09848338, 0.0685107 , 0.26202433, 0.17713753,\n",
       "         0.16850189, 0.32005654, 0.17295495, 0.38572039, 0.46655651,\n",
       "         0.00725049, 0.0644852 , 0.30267378, 0.63088768, 0.04550641,\n",
       "         0.35298459, 0.13753085, 0.84450412, 0.52286488, 0.9605947 ,\n",
       "         0.87861362, 0.0878376 , 0.12534199, 0.05023458, 0.96973691,\n",
       "         0.4255449 , 0.30219561, 0.22335549, 0.10457051, 0.27835554,\n",
       "         0.23416478, 0.44635538, 0.31755737, 0.23481232, 0.12385192,\n",
       "         0.15543692, 0.52232081, 0.19903154, 0.19072772, 0.05203983,\n",
       "         0.87217757, 0.12802155, 0.77515694, 0.75158936, 0.65594286,\n",
       "         0.04668114, 0.26687572, 0.00210051, 0.04989806, 0.34622475,\n",
       "         0.94790489, 0.8381326 , 0.37372773, 0.24316848, 0.35765151,\n",
       "         0.07778729, 0.48210011, 0.68668627, 0.97054858, 0.10004493,\n",
       "         0.68066726, 0.06411867, 0.10903359, 0.34112956, 0.37279491,\n",
       "         0.17343958, 0.42891336, 0.13909586, 0.03993994, 0.33295461,\n",
       "         0.13139801, 0.9485112 , 0.69366492, 0.0935751 , 0.87469974,\n",
       "         0.04971967, 0.55210567, 0.83368662, 0.52359534, 0.31360584,\n",
       "         0.89612807, 0.30165369, 0.33357874, 0.17797923, 0.38184963,\n",
       "         0.70966186, 0.6845619 , 0.41171032, 0.64226956, 0.07213422,\n",
       "         0.06055729, 0.11116644, 0.78329884, 0.95943339, 0.28852171,\n",
       "         0.69197801, 0.64966186, 0.03165361, 0.35779435, 0.04414077,\n",
       "         0.86690448, 0.88185956, 0.83721236, 0.79842189, 0.0415299 ,\n",
       "         0.05769569, 0.1190059 , 0.29648809, 0.45601879, 0.48057117,\n",
       "         0.93083847, 0.46561079, 0.70029198, 0.40791157, 0.08926672,\n",
       "         0.38245739, 0.17484976, 0.03507368, 0.07964614, 0.30874826,\n",
       "         0.21462646, 0.23522411, 0.11918239, 0.66743954, 0.90364617,\n",
       "         0.7649093 , 0.67219999, 0.15933609, 0.48423101, 0.3086462 ,\n",
       "         0.29619351, 0.71890697, 0.62045913, 0.0541583 , 0.51837171,\n",
       "         0.72639066, 0.07393632, 0.13308356, 0.04148721, 0.51731559,\n",
       "         0.2761123 , 0.18148926, 0.07974711, 0.27434203, 0.11225999,\n",
       "         0.48109716, 0.57088995, 0.37665923, 0.6345324 , 0.1222766 ,\n",
       "         0.45399772, 0.61943541, 0.45187015, 0.0605434 , 0.26288321,\n",
       "         0.05651653, 0.23795874, 0.64729101, 0.48542434, 0.44126202,\n",
       "         0.71889492, 0.25145161, 0.15229696, 0.48827848, 0.34073794,\n",
       "         0.82945887, 0.40035225, 0.09073991, 0.57548713, 0.24282347,\n",
       "         0.2985355 , 0.67477984, 0.12155494, 0.35731975, 0.3313852 ,\n",
       "         0.07996272, 0.21015135, 0.35456675, 0.22974372, 0.54156022,\n",
       "         0.18631143, 0.03835173, 0.70307281, 0.26245786, 0.77166057,\n",
       "         0.26697087, 0.15909884, 0.1515744 , 0.74187652, 0.17654048,\n",
       "         0.24386634, 0.31903943, 0.88684143, 0.21621035, 0.17798568,\n",
       "         0.48350072, 0.07944614, 0.94151566, 0.20510371, 0.04457196,\n",
       "         0.73648954, 0.56621477, 0.27408086, 0.77224334, 0.88928648,\n",
       "         0.16045169, 0.07661172, 0.00380806, 0.31789078, 0.39495484,\n",
       "         0.56104475, 0.3597763 , 0.20880196, 0.05549326, 0.01404014,\n",
       "         0.21481205, 0.32562764, 0.04996573, 0.06737391, 0.22535301,\n",
       "         0.74426603, 0.39785937, 0.92380795, 0.35075476, 0.86336075,\n",
       "         0.80370605, 0.65420746, 0.30989155, 0.75392789, 0.47022011,\n",
       "         0.24281229, 0.26770447, 0.03753524, 0.03566665, 0.21971532,\n",
       "         0.90523335, 0.0379946 , 0.0895923 , 0.16729733, 0.4280684 ,\n",
       "         0.80516864, 0.03729025, 0.12620786, 0.83099204, 0.24214405,\n",
       "         0.16064804, 0.03757054, 0.12318199, 0.10258963, 0.10320911,\n",
       "         0.09060344, 0.3464481 , 0.43649763, 0.50662165, 0.20547541,\n",
       "         0.12672194, 0.8630086 , 0.10066943, 0.12952441, 0.68299703,\n",
       "         0.39972633, 0.13917007, 0.25672762, 0.0313092 , 0.8250677 ,\n",
       "         0.12663452, 0.37147629, 0.43198074, 0.10805882, 0.72010149,\n",
       "         0.50012779, 0.23366822, 0.04701305, 0.92632233, 0.7469712 ,\n",
       "         0.27011652, 0.17831417, 0.60325174, 0.19970446, 0.35254567,\n",
       "         0.54029044, 0.12421393, 0.64557771, 0.02600515, 0.18664197,\n",
       "         0.37419355, 0.06605587, 0.21270865, 0.18593268, 0.81498349,\n",
       "         0.77470909, 0.01137648, 0.72336605, 0.32025208, 0.09844159,\n",
       "         0.09639969, 0.10385952, 0.04810418, 0.20132188, 0.10012083,\n",
       "         0.72373609, 0.74467672, 0.47172494, 0.02437813, 0.3489509 ,\n",
       "         0.72364981, 0.0782304 , 0.22800296, 0.39536998, 0.24162973,\n",
       "         0.99227423, 0.077457  , 0.09743011, 0.13907017, 0.13785157,\n",
       "         0.02419162, 0.28277959, 0.11738418, 0.41125576, 0.2231845 ,\n",
       "         0.91862449, 0.42927875, 0.08982488, 0.84937016, 0.58553928,\n",
       "         0.30792714, 0.02077461, 0.20377639, 0.08090053, 0.30912897,\n",
       "         0.09960163, 0.03110072, 0.15504343, 0.55434007, 0.83638241,\n",
       "         0.59916379, 0.26315834, 0.26311914, 0.41800246, 0.15692829,\n",
       "         0.24328256, 0.16879791, 0.16521979, 0.2732422 , 0.366948  ,\n",
       "         0.56140798, 0.19044028, 0.07391535, 0.06491397, 0.84448312,\n",
       "         0.41623295, 0.42744514, 0.92140521, 0.08500758, 0.89875197,\n",
       "         0.12945904, 0.0921466 , 0.14989689, 0.44093918, 0.00893811,\n",
       "         0.69797976, 0.14632363, 0.06035082, 0.80928708, 0.63468906,\n",
       "         0.08073233, 0.11859071, 0.02349765, 0.29544302, 0.18235412,\n",
       "         0.13997155, 0.67276313, 0.23843908, 0.12080088, 0.34302191,\n",
       "         0.21819817, 0.11107322, 0.14605343, 0.0758406 , 0.07227274,\n",
       "         0.53752468, 0.66586609, 0.5315326 , 0.23102271, 0.18379986,\n",
       "         0.01901339, 0.22876015, 0.04391115, 0.66593229, 0.25408915,\n",
       "         0.04472622, 0.02762877, 0.0973013 , 0.14083007, 0.11253535,\n",
       "         0.24945756, 0.35748017, 0.23590025, 0.29678775, 0.13774768,\n",
       "         0.57288805, 0.08564021, 0.02835283, 0.29558382, 0.44504301,\n",
       "         0.42137043, 0.29477537, 0.40779381, 0.10605402, 0.06687558,\n",
       "         0.84698458, 0.96092004, 0.298337  , 0.58573595, 0.73701329,\n",
       "         0.10472767, 0.09193381, 0.24822235, 0.06820592, 0.10720597,\n",
       "         0.20586557, 0.15425276, 0.27395951, 0.63906965, 0.17739115,\n",
       "         0.4182204 , 0.87577309, 0.11106434, 0.15849191, 0.08463866,\n",
       "         0.09559988, 0.16900017, 0.14935309, 0.52195324, 0.19171993,\n",
       "         0.07877369, 0.09451184, 0.17458978, 0.11843595, 0.29331856,\n",
       "         0.2871105 , 0.24054884, 0.43483521, 0.44654065, 0.92110364,\n",
       "         0.54179068, 0.14553483, 0.46184743, 0.3460226 , 0.31944687,\n",
       "         0.04759398, 0.64228427, 0.11242164, 0.84321642, 0.03774293,\n",
       "         0.81595368, 0.20885012, 0.41645957, 0.1751146 , 0.41814583,\n",
       "         0.6765681 , 0.10756277, 0.10433367, 0.68076703, 0.09682487,\n",
       "         0.07838974, 0.17248811, 0.13684235, 0.76317846, 0.85609996,\n",
       "         0.33317521, 0.85967413, 0.03520968, 0.48214083, 0.05893609,\n",
       "         0.14319915, 0.75608263, 0.83135984, 0.29156972, 0.76203068,\n",
       "         0.08762684, 0.16098145, 0.01490924, 0.51255059, 0.30360846,\n",
       "         0.19350245, 0.1515971 , 0.96104129, 0.16761202, 0.12121554,\n",
       "         0.14315229, 0.10132028, 0.22999418, 0.39129431, 0.05853674,\n",
       "         0.32533777, 0.09530925, 0.11612212, 0.10309374, 0.1402538 ,\n",
       "         0.42501373, 0.15921352, 0.10610489, 0.43421507, 0.0301739 ,\n",
       "         0.08506309, 0.34881315, 0.49908244, 0.23146255, 0.1239708 ,\n",
       "         0.49629571, 0.36812279, 0.76679607, 0.47287135, 0.0705292 ,\n",
       "         0.04460114, 0.23143409, 0.31326467, 0.19492315, 0.11010578,\n",
       "         0.51140125, 0.04653966, 0.46614646, 0.60836036, 0.15732647,\n",
       "         0.70266074, 0.96062283, 0.72327487, 0.76831425, 0.36634054,\n",
       "         0.13655566, 0.57098539, 0.27162706, 0.25080149, 0.63923497,\n",
       "         0.79862399, 0.07983625, 0.11232056, 0.7283863 , 0.36724572,\n",
       "         0.85628646, 0.56804996, 0.10548777, 0.32002845, 0.07081678,\n",
       "         0.01572825, 0.81235435, 0.20758368, 0.31546835, 0.07981031,\n",
       "         0.28454468, 0.16592901, 0.11664159, 0.22290491, 0.65413799,\n",
       "         0.23249262, 0.87150799, 0.4390656 , 0.61610772, 0.04245049,\n",
       "         0.30947559, 0.54442445, 0.10793766, 0.32859636, 0.62926354,\n",
       "         0.26263355, 0.36635249, 0.77422087, 0.67125486, 0.11006511,\n",
       "         0.15004582, 0.08097721, 0.24859282, 0.76384614, 0.18000749,\n",
       "         0.41428188, 0.32343765, 0.77275405, 0.14488828, 0.10106597,\n",
       "         0.90322656, 0.7709679 , 0.2078938 , 0.17858496, 0.2607099 ,\n",
       "         0.06436799, 0.20450064, 0.37865615, 0.365225  , 0.14742003,\n",
       "         0.33988409, 0.20573142, 0.28801066, 0.38045292, 0.07977737,\n",
       "         0.22845055, 0.22778409, 0.83387108, 0.11759936, 0.11486517,\n",
       "         0.18447613, 0.12163507, 0.1187914 , 0.16448267, 0.22641239,\n",
       "         0.76717464, 0.16782463, 0.09565869, 0.66091737, 0.92924191,\n",
       "         0.31217664, 0.69281453, 0.31132845, 0.82614966, 0.57279668,\n",
       "         0.54352397, 0.27592134, 0.10670918, 0.66567141, 0.72366832,\n",
       "         0.44174397, 0.48015936, 0.31866953, 0.16483335, 0.90090307,\n",
       "         0.09695624, 0.93467837, 0.08814316, 0.31900435, 0.31859379,\n",
       "         0.1714758 , 0.28563864, 0.0727153 ])}}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(X.values, y.values, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b2ddaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(x: np.ndarray, y: np.ndarray) -> dict:\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    svm_results = {}\n",
    "    for kernel in kernels:\n",
    "        svm_model = SVC(kernel=kernel, probability=True, max_iter=1000)\n",
    "        scores = cross_val_score(svm_model, x, y, cv=kf, scoring='precision')\n",
    "        svm_results[kernel] = {\n",
    "            'mean': scores.mean(),\n",
    "            'std': scores.std()\n",
    "        }\n",
    "\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(x, y)\n",
    "    lr_scores = cross_val_score(lr_model, x, y, cv=kf, scoring='precision')\n",
    "    lr_predict = lr_model.predict_proba(x)[:, 1]\n",
    "    lr_results = {\n",
    "        'mean': lr_scores.mean(),\n",
    "        'std': lr_scores.std(),\n",
    "        'predictions': lr_predict\n",
    "    }\n",
    "\n",
    "    print(\"SVM Results:\")\n",
    "    for kernel, result in svm_results.items():\n",
    "        print(f\"{kernel}: precision = {result['mean']:.4f} ± {result['std']:.4f}\")\n",
    "    print(\n",
    "        f\"\\nLogistic Regression: precision = {lr_results['mean']:.4f} ± {lr_results['std']:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'svm_results': svm_results,\n",
    "        'lr_results': lr_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1b08d2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "linear: precision = 0.7057 ± 0.1294\n",
      "rbf: precision = 0.7184 ± 0.1299\n",
      "poly: precision = 0.7605 ± 0.0986\n",
      "\n",
      "Logistic Regression: precision = 0.7298 ± 0.0872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svm_results': {'linear': {'mean': np.float64(0.7057385762385762),\n",
       "   'std': np.float64(0.12938284080075063)},\n",
       "  'rbf': {'mean': np.float64(0.7183552738970695),\n",
       "   'std': np.float64(0.1298844407014)},\n",
       "  'poly': {'mean': np.float64(0.7605013368983957),\n",
       "   'std': np.float64(0.09857943553197901)}},\n",
       " 'lr_results': {'mean': np.float64(0.7297658529781292),\n",
       "  'std': np.float64(0.08721060921784003),\n",
       "  'predictions': array([0.71788557, 0.05004217, 0.7916649 , 0.04292874, 0.89864691,\n",
       "         0.14842183, 0.06808818, 0.63750014, 0.70997257, 0.03807967,\n",
       "         0.22122976, 0.89393557, 0.78146623, 0.6337848 , 0.62645407,\n",
       "         0.39738602, 0.37235677, 0.19810911, 0.35598437, 0.23576997,\n",
       "         0.39330902, 0.3185104 , 0.93786761, 0.29480507, 0.70010361,\n",
       "         0.44101334, 0.73329128, 0.04727481, 0.53929577, 0.27939413,\n",
       "         0.42647917, 0.5716599 , 0.05034582, 0.03780712, 0.43187454,\n",
       "         0.15193868, 0.66127902, 0.39334987, 0.1735713 , 0.57246524,\n",
       "         0.73887433, 0.6926571 , 0.11627473, 0.92515896, 0.62521318,\n",
       "         0.94990929, 0.43202883, 0.04098976, 0.37956448, 0.03986138,\n",
       "         0.03749065, 0.08672076, 0.06897989, 0.82526127, 0.70684618,\n",
       "         0.02349474, 0.88029203, 0.35837466, 0.82964008, 0.18471886,\n",
       "         0.01032847, 0.51924463, 0.02437444, 0.30859252, 0.35433509,\n",
       "         0.12041188, 0.19449076, 0.471383  , 0.03312359, 0.30275219,\n",
       "         0.19521642, 0.36390009, 0.81352824, 0.24856769, 0.05297115,\n",
       "         0.00210559, 0.07824708, 0.22300333, 0.66486304, 0.10174511,\n",
       "         0.10364212, 0.00616639, 0.13937028, 0.05135108, 0.67255807,\n",
       "         0.19385721, 0.52750281, 0.18851854, 0.78109638, 0.07584466,\n",
       "         0.02002706, 0.26047819, 0.33183473, 0.29813446, 0.25565044,\n",
       "         0.51530937, 0.08335021, 0.0180366 , 0.13542119, 0.45204381,\n",
       "         0.83257741, 0.28198402, 0.06418534, 0.03292025, 0.23208479,\n",
       "         0.24780365, 0.02042406, 0.42466657, 0.108202  , 0.09487402,\n",
       "         0.59775931, 0.70659129, 0.05542445, 0.0949544 , 0.73665918,\n",
       "         0.55325455, 0.35675488, 0.15928957, 0.11951508, 0.0541797 ,\n",
       "         0.88258148, 0.28450174, 0.15078459, 0.35608822, 0.13743818,\n",
       "         0.52305771, 0.45697679, 0.19609191, 0.19697618, 0.15746995,\n",
       "         0.63012116, 0.68074757, 0.66994572, 0.27331335, 0.05643361,\n",
       "         0.24395448, 0.09930611, 0.06930825, 0.26248807, 0.17866197,\n",
       "         0.1700225 , 0.32029731, 0.17346228, 0.38554744, 0.46604519,\n",
       "         0.00745898, 0.06541007, 0.30326581, 0.63018036, 0.04613325,\n",
       "         0.35311426, 0.13854645, 0.84290125, 0.5232295 , 0.95957638,\n",
       "         0.87656118, 0.08864848, 0.12628821, 0.05094959, 0.96894917,\n",
       "         0.42502866, 0.30307878, 0.22471488, 0.1052561 , 0.27893459,\n",
       "         0.23556719, 0.44472541, 0.3176704 , 0.23523254, 0.12503067,\n",
       "         0.15650991, 0.52115783, 0.19881975, 0.19118321, 0.05283464,\n",
       "         0.87028685, 0.12922758, 0.77310705, 0.7496119 , 0.6540884 ,\n",
       "         0.04743989, 0.26716085, 0.00218093, 0.05058131, 0.34639707,\n",
       "         0.94663077, 0.83761892, 0.37400458, 0.24399292, 0.35774735,\n",
       "         0.07849914, 0.48141979, 0.68436039, 0.96955705, 0.10101736,\n",
       "         0.6790186 , 0.06479299, 0.10986614, 0.34093155, 0.37335504,\n",
       "         0.17409539, 0.42805683, 0.1400063 , 0.0406062 , 0.33444317,\n",
       "         0.13219342, 0.94767339, 0.69242281, 0.09440086, 0.87272924,\n",
       "         0.05036594, 0.54997205, 0.83210529, 0.52209049, 0.31450793,\n",
       "         0.89465487, 0.30175257, 0.33382327, 0.17886049, 0.3816682 ,\n",
       "         0.70848132, 0.68383451, 0.41010137, 0.64180189, 0.07299386,\n",
       "         0.06130329, 0.1120406 , 0.78021311, 0.95887782, 0.28860256,\n",
       "         0.68939321, 0.64948089, 0.03222971, 0.35734703, 0.04479347,\n",
       "         0.8645643 , 0.88054969, 0.83472464, 0.79602816, 0.04221562,\n",
       "         0.05834496, 0.11987824, 0.29606923, 0.45556587, 0.48002338,\n",
       "         0.92952842, 0.46482273, 0.70031005, 0.40895783, 0.0901078 ,\n",
       "         0.38211727, 0.17568269, 0.03570694, 0.08039607, 0.3102506 ,\n",
       "         0.21479135, 0.23543343, 0.11992521, 0.66603805, 0.90231929,\n",
       "         0.76279015, 0.66868744, 0.15995989, 0.4844348 , 0.30870513,\n",
       "         0.29709797, 0.71530487, 0.61778994, 0.05477814, 0.51553943,\n",
       "         0.7242176 , 0.07467145, 0.13425142, 0.04211877, 0.51666327,\n",
       "         0.27619859, 0.18204183, 0.08064143, 0.27566703, 0.11352744,\n",
       "         0.47967141, 0.56981978, 0.37729929, 0.6331524 , 0.12368868,\n",
       "         0.45443118, 0.61984003, 0.45186674, 0.06129164, 0.26341363,\n",
       "         0.05728762, 0.23836485, 0.64583118, 0.48415882, 0.44149582,\n",
       "         0.71650579, 0.25294942, 0.15360111, 0.48845654, 0.34173925,\n",
       "         0.82638732, 0.3997098 , 0.09176508, 0.57379466, 0.24356536,\n",
       "         0.29888121, 0.67340186, 0.12254169, 0.35757595, 0.33199771,\n",
       "         0.08092507, 0.21090116, 0.35451315, 0.23015492, 0.54050007,\n",
       "         0.18711569, 0.03906771, 0.70054525, 0.26298064, 0.77005482,\n",
       "         0.26800079, 0.15975306, 0.15252191, 0.73998173, 0.17700936,\n",
       "         0.24461568, 0.31942736, 0.88483718, 0.21698502, 0.17900935,\n",
       "         0.4830015 , 0.08024003, 0.93991312, 0.20624001, 0.04521853,\n",
       "         0.73456735, 0.56390722, 0.2748989 , 0.77032133, 0.88747485,\n",
       "         0.16133965, 0.07766714, 0.00393297, 0.31814279, 0.39549091,\n",
       "         0.56058935, 0.35902642, 0.20846484, 0.05626024, 0.01440813,\n",
       "         0.21546203, 0.32568076, 0.05085543, 0.06815834, 0.22571015,\n",
       "         0.74252089, 0.39744159, 0.92190907, 0.35126021, 0.86160927,\n",
       "         0.80194813, 0.65315785, 0.31158685, 0.75267578, 0.47028515,\n",
       "         0.24325792, 0.26797602, 0.03809606, 0.0363126 , 0.22146246,\n",
       "         0.90407143, 0.0386588 , 0.09040442, 0.16799435, 0.42736251,\n",
       "         0.80436346, 0.0379578 , 0.12696744, 0.8285916 , 0.24329457,\n",
       "         0.16152461, 0.03814398, 0.12425132, 0.10350625, 0.10418802,\n",
       "         0.0913855 , 0.34633481, 0.43642346, 0.50779375, 0.20628267,\n",
       "         0.12820076, 0.86067828, 0.10209908, 0.13076001, 0.68072105,\n",
       "         0.3999619 , 0.14037828, 0.25658665, 0.03186851, 0.82233809,\n",
       "         0.12750189, 0.37189261, 0.43165492, 0.10910621, 0.71781179,\n",
       "         0.49875099, 0.23471203, 0.04767558, 0.924815  , 0.74619269,\n",
       "         0.27044185, 0.17938729, 0.60237747, 0.20027336, 0.35228437,\n",
       "         0.54043702, 0.12496493, 0.64356999, 0.02651953, 0.18749635,\n",
       "         0.37436311, 0.0668561 , 0.2130853 , 0.1863063 , 0.81320086,\n",
       "         0.77298836, 0.0116194 , 0.72155768, 0.32072517, 0.09988862,\n",
       "         0.09679414, 0.10507026, 0.04882894, 0.2020011 , 0.10116216,\n",
       "         0.72017613, 0.74246505, 0.47046389, 0.02483454, 0.34899055,\n",
       "         0.72182404, 0.07902352, 0.22855514, 0.39491495, 0.24194183,\n",
       "         0.99195052, 0.07841073, 0.09840796, 0.13980772, 0.13878422,\n",
       "         0.02469334, 0.28273441, 0.11853812, 0.411318  , 0.22362876,\n",
       "         0.91685459, 0.42958729, 0.09068894, 0.8480947 , 0.58593667,\n",
       "         0.30883988, 0.02120726, 0.20474214, 0.08186741, 0.3097514 ,\n",
       "         0.10045673, 0.03161769, 0.15589712, 0.55169126, 0.83418704,\n",
       "         0.59698516, 0.26302389, 0.26298128, 0.41832269, 0.1575547 ,\n",
       "         0.24475949, 0.17008318, 0.16636626, 0.27396428, 0.36800768,\n",
       "         0.56111002, 0.19118238, 0.07473025, 0.06581151, 0.84151805,\n",
       "         0.41604242, 0.42803789, 0.92043315, 0.08585348, 0.89744342,\n",
       "         0.13029798, 0.09329103, 0.15069441, 0.44119846, 0.00913969,\n",
       "         0.69687925, 0.14717442, 0.06118458, 0.80775213, 0.63359818,\n",
       "         0.08166272, 0.11940288, 0.02401845, 0.29611762, 0.18332219,\n",
       "         0.14110599, 0.67105154, 0.2390411 , 0.12155106, 0.34427613,\n",
       "         0.21916825, 0.11213769, 0.14753096, 0.0765799 , 0.07306256,\n",
       "         0.53608877, 0.66521794, 0.53101472, 0.23172691, 0.18650435,\n",
       "         0.01943698, 0.2295789 , 0.0443903 , 0.66413293, 0.25408009,\n",
       "         0.04532329, 0.02815104, 0.09827642, 0.14187848, 0.11346767,\n",
       "         0.24982197, 0.35698648, 0.23639805, 0.29597873, 0.13852716,\n",
       "         0.56948907, 0.08686221, 0.02908608, 0.29628171, 0.44500312,\n",
       "         0.42195383, 0.29545435, 0.40829841, 0.10704555, 0.06778773,\n",
       "         0.84538846, 0.96012739, 0.2988417 , 0.58486893, 0.73508714,\n",
       "         0.10543267, 0.0928822 , 0.25005667, 0.06895933, 0.1082223 ,\n",
       "         0.20725461, 0.15498428, 0.27526807, 0.63695629, 0.17831446,\n",
       "         0.41847796, 0.87400963, 0.11193899, 0.15938936, 0.08555337,\n",
       "         0.09644026, 0.16955736, 0.15071601, 0.5211194 , 0.19285608,\n",
       "         0.0797655 , 0.09542532, 0.17509067, 0.11932   , 0.29462825,\n",
       "         0.2867729 , 0.24129644, 0.43365537, 0.44567668, 0.91965408,\n",
       "         0.5397091 , 0.14617963, 0.46211464, 0.34626965, 0.32272394,\n",
       "         0.04820872, 0.64029577, 0.11328811, 0.84186849, 0.03819435,\n",
       "         0.81388451, 0.20963168, 0.41640545, 0.17598216, 0.41839473,\n",
       "         0.67471392, 0.10878339, 0.10484307, 0.6786186 , 0.09766786,\n",
       "         0.0792493 , 0.17256571, 0.13766505, 0.76180736, 0.85332034,\n",
       "         0.33236534, 0.85788622, 0.03580073, 0.48192657, 0.05980755,\n",
       "         0.14412674, 0.75415463, 0.83008029, 0.29162014, 0.76052893,\n",
       "         0.08848572, 0.16201892, 0.01524906, 0.51211327, 0.30243309,\n",
       "         0.19463719, 0.15253119, 0.96012132, 0.16841326, 0.1218988 ,\n",
       "         0.14415549, 0.10207191, 0.23032282, 0.39141769, 0.05919227,\n",
       "         0.32533613, 0.09624185, 0.11684401, 0.10422691, 0.1410753 ,\n",
       "         0.42448593, 0.1605052 , 0.10704206, 0.4337489 , 0.03076092,\n",
       "         0.08614528, 0.34824616, 0.49865305, 0.23122957, 0.12511396,\n",
       "         0.49677184, 0.36844407, 0.76411321, 0.47277205, 0.07121383,\n",
       "         0.04526608, 0.23201999, 0.31332486, 0.19539046, 0.11106275,\n",
       "         0.51171509, 0.04720155, 0.46641754, 0.6075943 , 0.15837365,\n",
       "         0.7011841 , 0.95945631, 0.72227766, 0.76643234, 0.36596248,\n",
       "         0.13757338, 0.57089413, 0.27209541, 0.25204219, 0.63791559,\n",
       "         0.7970432 , 0.080537  , 0.11381265, 0.72668742, 0.36859959,\n",
       "         0.85396426, 0.5673682 , 0.10625212, 0.31945124, 0.0718574 ,\n",
       "         0.01607574, 0.80964408, 0.20810861, 0.31545972, 0.08130382,\n",
       "         0.28529673, 0.16649164, 0.11735796, 0.22385394, 0.65313272,\n",
       "         0.23329659, 0.8698525 , 0.43810569, 0.61474588, 0.04307273,\n",
       "         0.31204595, 0.54323282, 0.10827776, 0.32924856, 0.62688182,\n",
       "         0.26352525, 0.36672114, 0.77248712, 0.66823058, 0.11109896,\n",
       "         0.15082389, 0.08152456, 0.24951709, 0.76178153, 0.18090359,\n",
       "         0.41480821, 0.32381968, 0.77016655, 0.14610633, 0.10202429,\n",
       "         0.90184399, 0.76903676, 0.20929302, 0.17946259, 0.26177413,\n",
       "         0.0652748 , 0.20533254, 0.37904086, 0.36582624, 0.14882436,\n",
       "         0.33987881, 0.20679052, 0.28795454, 0.37984771, 0.08045377,\n",
       "         0.22937812, 0.2282193 , 0.8316562 , 0.11854517, 0.1162649 ,\n",
       "         0.18495803, 0.1226872 , 0.11991063, 0.16536274, 0.22736522,\n",
       "         0.76566308, 0.1684925 , 0.09652961, 0.65950488, 0.92794432,\n",
       "         0.3132476 , 0.69031769, 0.31158577, 0.82430422, 0.57157116,\n",
       "         0.5415227 , 0.27628643, 0.10743857, 0.66526269, 0.72160442,\n",
       "         0.44174953, 0.47935448, 0.31947814, 0.16558767, 0.89963721,\n",
       "         0.09767876, 0.93323626, 0.08903045, 0.32079676, 0.31827591,\n",
       "         0.17251606, 0.28630598, 0.07344453])}}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels = ['linear', 'rbf', 'poly']\n",
    "run_model(X.values, y.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
